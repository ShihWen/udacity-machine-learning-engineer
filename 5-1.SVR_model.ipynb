{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abstract-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-chest",
   "metadata": {},
   "source": [
    "## 0. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lovely-shopper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_presr</th>\n",
       "      <th>temp_℃</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_spd_m_s</th>\n",
       "      <th>precipitation＿mm_t</th>\n",
       "      <th>time</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 01:00:00</th>\n",
       "      <td>1020.4</td>\n",
       "      <td>13.8</td>\n",
       "      <td>86</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 06:00:00</th>\n",
       "      <td>1020.1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>92</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 07:00:00</th>\n",
       "      <td>1020.7</td>\n",
       "      <td>14.1</td>\n",
       "      <td>93</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:00:00</th>\n",
       "      <td>1021.3</td>\n",
       "      <td>14.4</td>\n",
       "      <td>92</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 09:00:00</th>\n",
       "      <td>1021.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>89</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     air_presr  temp_℃  humidity  wind_spd_m_s  \\\n",
       "datetime                                                         \n",
       "2020-01-01 01:00:00     1020.4    13.8        86           1.6   \n",
       "2020-01-01 06:00:00     1020.1    13.9        92           2.3   \n",
       "2020-01-01 07:00:00     1020.7    14.1        93           2.4   \n",
       "2020-01-01 08:00:00     1021.3    14.4        92           1.6   \n",
       "2020-01-01 09:00:00     1021.7    15.0        89           1.6   \n",
       "\n",
       "                     precipitation＿mm_t  time  people  \n",
       "datetime                                               \n",
       "2020-01-01 01:00:00                 0.0     1       8  \n",
       "2020-01-01 06:00:00                 0.0     6    1357  \n",
       "2020-01-01 07:00:00                 0.0     7    1421  \n",
       "2020-01-01 08:00:00                 0.0     8    1785  \n",
       "2020-01-01 09:00:00                 0.0     9    2841  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_presr</th>\n",
       "      <th>temp_℃</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_spd_m_s</th>\n",
       "      <th>precipitation＿mm_t</th>\n",
       "      <th>time</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>air_presr</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545295</td>\n",
       "      <td>0.664944</td>\n",
       "      <td>0.208620</td>\n",
       "      <td>-0.015630</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>-0.002400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp_℃</th>\n",
       "      <td>0.545295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.106830</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>-0.024059</td>\n",
       "      <td>0.059052</td>\n",
       "      <td>0.065682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>0.664944</td>\n",
       "      <td>0.106830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049035</td>\n",
       "      <td>0.092039</td>\n",
       "      <td>-0.052849</td>\n",
       "      <td>-0.089997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind_spd_m_s</th>\n",
       "      <td>0.208620</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>0.049035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014389</td>\n",
       "      <td>0.113611</td>\n",
       "      <td>0.128371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipitation＿mm_t</th>\n",
       "      <td>-0.015630</td>\n",
       "      <td>-0.024059</td>\n",
       "      <td>0.092039</td>\n",
       "      <td>-0.014389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.020481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.059052</td>\n",
       "      <td>-0.052849</td>\n",
       "      <td>0.113611</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.492923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>-0.002400</td>\n",
       "      <td>0.065682</td>\n",
       "      <td>-0.089997</td>\n",
       "      <td>0.128371</td>\n",
       "      <td>0.020481</td>\n",
       "      <td>0.492923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    air_presr    temp_℃  humidity  wind_spd_m_s  \\\n",
       "air_presr            1.000000  0.545295  0.664944      0.208620   \n",
       "temp_℃               0.545295  1.000000  0.106830      0.016241   \n",
       "humidity             0.664944  0.106830  1.000000      0.049035   \n",
       "wind_spd_m_s         0.208620  0.016241  0.049035      1.000000   \n",
       "precipitation＿mm_t  -0.015630 -0.024059  0.092039     -0.014389   \n",
       "time                 0.016148  0.059052 -0.052849      0.113611   \n",
       "people              -0.002400  0.065682 -0.089997      0.128371   \n",
       "\n",
       "                    precipitation＿mm_t      time    people  \n",
       "air_presr                    -0.015630  0.016148 -0.002400  \n",
       "temp_℃                       -0.024059  0.059052  0.065682  \n",
       "humidity                      0.092039 -0.052849 -0.089997  \n",
       "wind_spd_m_s                 -0.014389  0.113611  0.128371  \n",
       "precipitation＿mm_t            1.000000  0.006337  0.020481  \n",
       "time                          0.006337  1.000000  0.492923  \n",
       "people                        0.020481  0.492923  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and Merge data\n",
    "station = 'tch'\n",
    "\n",
    "dateparse = lambda x: datetime.strptime(x, '%Y-%m-%d')\n",
    "df_traffic = pd.read_csv('data/traffic_{}_all.csv'.format(station),\n",
    "                 parse_dates={'Date': ['date']}, \n",
    "                 date_parser=dateparse)\n",
    "\n",
    "df_traffic['datetime'] = df_traffic['Date'] + df_traffic['time'].astype('timedelta64[h]')\n",
    "df_traffic = df_traffic[['datetime','time','people']]\n",
    "\n",
    "df_weather = pd.read_csv('data/weather_{}_all.csv'.format(station))\n",
    "df_weather['datetime'] = pd.to_datetime(df_weather['datetime'])\n",
    "\n",
    "df = df_weather.merge(df_traffic,on='datetime')\n",
    "df.set_index('datetime',inplace=True)#.asfreq('1H') #generate missing hours\n",
    "#df.fillna(0,inplace=True) #fill missing hours with 0\n",
    "display(df.head())\n",
    "display(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "humanitarian-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc['2020-01-01':'2020-11-30']\n",
    "df_test = df.loc['2020-12-01':'2020-12-31']\n",
    "\n",
    "\n",
    "df_train.to_csv('{}_data/train_{}.csv'.format(station, station), index=False)\n",
    "df_test.to_csv('{}_data/test_{}.csv'.format(station, station), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "concerned-narrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024.9</td>\n",
       "      <td>14.8</td>\n",
       "      <td>82</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1024.4</td>\n",
       "      <td>14.9</td>\n",
       "      <td>87</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1025.2</td>\n",
       "      <td>14.9</td>\n",
       "      <td>90</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1025.6</td>\n",
       "      <td>15.4</td>\n",
       "      <td>89</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1026.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>82</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>1020.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>92</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>1021.3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>89</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>1021.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>89</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>1021.5</td>\n",
       "      <td>18.3</td>\n",
       "      <td>95</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>1021.1</td>\n",
       "      <td>18.3</td>\n",
       "      <td>96</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1   2    3    4   5\n",
       "0     1024.9  14.8  82  3.6  0.0   1\n",
       "1     1024.4  14.9  87  4.1  0.0   6\n",
       "2     1025.2  14.9  90  3.1  0.0   7\n",
       "3     1025.6  15.4  89  3.5  0.0   8\n",
       "4     1026.0  16.4  82  4.5  0.0   9\n",
       "...      ...   ...  ..  ...  ...  ..\n",
       "7028  1020.9  18.8  92  3.7  0.0  19\n",
       "7029  1021.3  19.0  89  3.7  0.0  20\n",
       "7030  1021.4  19.0  89  3.1  0.0  21\n",
       "7031  1021.5  18.3  95  4.2  0.5  22\n",
       "7032  1021.1  18.3  96  2.9  0.5  23\n",
       "\n",
       "[7033 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"tms_data/train_tms.csv\", skiprows=1, header=None, names=None)\n",
    "train_data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aging-conclusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.997664</td>\n",
       "      <td>0.224359</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997177</td>\n",
       "      <td>0.227564</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.471264</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.109371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997956</td>\n",
       "      <td>0.227564</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.356322</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.158553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998345</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.232941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.998735</td>\n",
       "      <td>0.275641</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.246980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>0.993770</td>\n",
       "      <td>0.352564</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.425287</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.403368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>0.994159</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.425287</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.278636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>0.994257</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.356322</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.268973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>0.994354</td>\n",
       "      <td>0.336538</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.262068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>0.993965</td>\n",
       "      <td>0.336538</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3       4         5         6\n",
       "0     0.997664  0.224359  0.763158  0.413793  0.0000  0.043478  0.000387\n",
       "1     0.997177  0.227564  0.828947  0.471264  0.0000  0.260870  0.109371\n",
       "2     0.997956  0.227564  0.868421  0.356322  0.0000  0.304348  0.158553\n",
       "3     0.998345  0.243590  0.855263  0.402299  0.0000  0.347826  0.232941\n",
       "4     0.998735  0.275641  0.763158  0.517241  0.0000  0.391304  0.246980\n",
       "...        ...       ...       ...       ...     ...       ...       ...\n",
       "7028  0.993770  0.352564  0.894737  0.425287  0.0000  0.826087  0.403368\n",
       "7029  0.994159  0.358974  0.855263  0.425287  0.0000  0.869565  0.278636\n",
       "7030  0.994257  0.358974  0.855263  0.356322  0.0000  0.913043  0.268973\n",
       "7031  0.994354  0.336538  0.934211  0.482759  0.0125  0.956522  0.262068\n",
       "7032  0.993965  0.336538  0.947368  0.333333  0.0125  1.000000  0.074434\n",
       "\n",
       "[7033 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# store them in this dataframe\n",
    "train_x=pd.DataFrame(scaler.fit_transform(df_train.astype(float)))\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accepted-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train df\n",
    "df_train_X = df.loc['2020-01-01':'2020-11-30', :'time']\n",
    "df_train_y = df.loc['2020-01-01':'2020-11-30', 'people']\n",
    "# Normalize and split data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# store them in this dataframe\n",
    "df_scaled=pd.DataFrame(scaler.fit_transform(df_train_X.astype(float)))\n",
    "\n",
    "# get same features and State-County indices\n",
    "df_scaled.columns=df_train_X.columns\n",
    "df_scaled.index=df_train_X.index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_scaled.to_csv('{}_data/train_{}_X.csv'.format(station, station), index=False)\n",
    "df_train_y.to_csv('{}_data/train_{}_y.csv'.format(station, station),index=False)\n",
    "\n",
    "\n",
    "#test df\n",
    "df_test_X = df.loc['2020-12-01':'2020-12-31', :'time']\n",
    "df_test_y = df.loc['2020-12-01':'2020-12-31', 'people']\n",
    "# Normalize and split data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# store them in this dataframe\n",
    "df_scaled=pd.DataFrame(scaler.fit_transform(df_test_X.astype(float)))\n",
    "\n",
    "# get same features and State-County indices\n",
    "df_scaled.columns=df_test_X.columns\n",
    "df_scaled.index=df_test_X.index\n",
    "\n",
    "df_scaled.to_csv('{}_data/test_{}_X.csv'.format(station, station),index=False)\n",
    "df_test_y.to_csv('{}_data/test_{}_y.csv'.format(station, station),index=False)\n",
    "\n",
    "#df_train_y = df.iloc[:, -1].set_index('datetime')\n",
    "# convert df to np array\n",
    "#train_X_np = df_scaled.values.astype('float32')\n",
    "#train_y_np  = df_train_y.values.reshape(df_train_y.shape[0],1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-county",
   "metadata": {},
   "source": [
    "## 1. Upload Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sufficient-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "premium-spider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-716934411671/capStoneProject_tms_data\n"
     ]
    }
   ],
   "source": [
    "# should be the name of directory you created to save your features data\n",
    "data_dir = '{}_data'.format(station)\n",
    "\n",
    "# directories to save train/test data\n",
    "#train_key = os.path.join(data_dir, '{}_train.csv')\n",
    "#test_key = os.path.join(data_dir, '{}_test.csv')\n",
    "\n",
    "\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'capStoneProject_{}_data'.format(station)\n",
    "\n",
    "# upload all data to S3\n",
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "close-banana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpreprocessing\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m MinMaxScaler\n",
      "\n",
      "\u001b[37m# sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. \u001b[39;49;00m\n",
      "\u001b[37m#from sklearn.externals import joblib\u001b[39;49;00m\n",
      "\u001b[37m# Import joblib package directly\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjoblib\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m## TODO: Import any additional libraries you need to define a model\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msvm\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SVR\n",
      "\u001b[37m#from sklearn import linear_model\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# Provided model load function\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    \u001b[33m\"\"\"Load model from the model_dir. This is the same model that is saved\u001b[39;49;00m\n",
      "\u001b[33m    in the main if statement.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[37m# load using joblib\u001b[39;49;00m\n",
      "    model = joblib.load(os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.joblib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDone loading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[34mreturn\u001b[39;49;00m model\n",
      "\n",
      "\n",
      "\u001b[37m## TODO: Complete the main code\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    \n",
      "    \u001b[37m# All of the model parameters and training parameters are sent as arguments\u001b[39;49;00m\n",
      "    \u001b[37m# when this script is executed, during a training job\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[37m# Here we set up an argument parser to easily access the parameters\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# SageMaker parameters, like the directories for training data and saving models; set automatically\u001b[39;49;00m\n",
      "    \u001b[37m# Do not need to change\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output-data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    \n",
      "    \u001b[37m## TODO: Add any additional arguments that you will need to pass into your model\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[37m# args holds all passed-in arguments\u001b[39;49;00m\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    \u001b[37m# Read in csv training file\u001b[39;49;00m\n",
      "    training_dir = args.data_dir\n",
      "    train_data = pd.read_csv(os.path.join(training_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain_tms.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), skiprows=\u001b[34m1\u001b[39;49;00m, header=\u001b[34mNone\u001b[39;49;00m, names=\u001b[34mNone\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Labels are in the first column\u001b[39;49;00m\n",
      "    train_y = train_data.iloc[:,-\u001b[34m1\u001b[39;49;00m]\n",
      "    train_x = train_data.iloc[:,:-\u001b[34m1\u001b[39;49;00m]\n",
      "    \n",
      "    \u001b[37m# Normalize and split data\u001b[39;49;00m\n",
      "    scaler = MinMaxScaler()\n",
      "\n",
      "    \u001b[37m# store them in this dataframe\u001b[39;49;00m\n",
      "    train_x=pd.DataFrame(scaler.fit_transform(train_x.astype(\u001b[36mfloat\u001b[39;49;00m)))\n",
      "    \n",
      "\n",
      "    \n",
      "    \n",
      "    \n",
      "    \u001b[37m## --- Your code here --- ##\u001b[39;49;00m\n",
      "    \n",
      "\n",
      "    \u001b[37m## TODO: Define a model \u001b[39;49;00m\n",
      "    \u001b[37m#model = None\u001b[39;49;00m\n",
      "    \u001b[37m#model = linear_model.LogisticRegression()\u001b[39;49;00m\n",
      "    model = SVR(kernel=\u001b[33m'\u001b[39;49;00m\u001b[33mrbf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                C=\u001b[34m100\u001b[39;49;00m,\n",
      "                gamma=\u001b[34m0.1\u001b[39;49;00m,\n",
      "                epsilon=\u001b[34m0.1\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[37m## TODO: Train the model\u001b[39;49;00m\n",
      "    model.fit(train_x, train_y)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \u001b[37m## --- End of your code  --- ##\u001b[39;49;00m\n",
      "    \n",
      "\n",
      "    \u001b[37m# Save the trained model\u001b[39;49;00m\n",
      "    joblib.dump(model, os.path.join(args.model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.joblib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n"
     ]
    }
   ],
   "source": [
    "!pygmentize source_sklearn/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-cycling",
   "metadata": {},
   "source": [
    "## 2. Train a Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "funky-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(os.path.join(\"tms_data\", \"train_tms_y.csv\"), skiprows = 1,header = None).iloc[:,0]\n",
    "#pd.read_csv(os.path.join(\"tms_data\", \"train_tms_X.csv\"), skiprows = 1,header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "behind-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "# output path\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# your import and estimator code, here\n",
    "sklearn_estimator = SKLearn(entry_point='train.py',\n",
    "                            source_dir='source_sklearn',\n",
    "                            role=role,\n",
    "                            framework_version='0.23-1',\n",
    "                            instance_count=1,\n",
    "                            instance_type='ml.m4.xlarge',\n",
    "                            output_path=output_path,\n",
    "                            sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abandoned-religious",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-20 06:54:30 Starting - Starting the training job...\n",
      "2021-03-20 06:54:33 Starting - Launching requested ML instancesProfilerReport-1616223270: InProgress\n",
      "......\n",
      "2021-03-20 06:56:00 Starting - Preparing the instances for training.........\n",
      "2021-03-20 06:57:26 Downloading - Downloading input data......\n",
      "2021-03-20 06:58:29 Training - Training image download completed. Training in progress..\u001b[34m2021-03-20 06:58:30,180 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2021-03-20 06:58:30,183 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-03-20 06:58:30,193 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-03-20 06:59:31,021 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-03-20 06:59:31,034 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-03-20 06:59:31,047 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-03-20 06:59:31,058 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2021-03-20-06-54-30-226\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-716934411671/sagemaker-scikit-learn-2021-03-20-06-54-30-226/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-716934411671/sagemaker-scikit-learn-2021-03-20-06-54-30-226/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2021-03-20-06-54-30-226\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-716934411671/sagemaker-scikit-learn-2021-03-20-06-54-30-226/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python train.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021-03-20 06:59:35,777 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-03-20 06:59:48 Uploading - Uploading generated training model\n",
      "2021-03-20 06:59:48 Completed - Training job completed\n",
      "Training seconds: 158\n",
      "Billable seconds: 158\n",
      "CPU times: user 817 ms, sys: 36.9 ms, total: 854 ms\n",
      "Wall time: 5min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train your estimator on S3 training data\n",
    "sklearn_estimator.fit({'train': os.path.join(input_data, 'train_tms.csv'),\n",
    "                       'test': os.path.join(input_data, 'test_tms.csv')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-insert",
   "metadata": {},
   "source": [
    "## 3. Deploy the trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lesser-lindsay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "# deploy your model to create a predictor\n",
    "predictor = sklearn_estimator.deploy(instance_type='ml.m4.xlarge',\n",
    "                                     initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-characteristic",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "curious-synthetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(651, 6) (651,)\n"
     ]
    }
   ],
   "source": [
    "# read in test data, assuming it is stored locally\n",
    "test_data = pd.read_csv(os.path.join('{}_data'.format(station), \"test_tms.csv\"), skiprows=1, header=None, names=None)\n",
    "\n",
    "\n",
    "\n",
    "# labels are in the first column\n",
    "test_y = test_data.iloc[:,-1]\n",
    "test_x = test_data.iloc[:,:-1]\n",
    "print(test_x.shape, test_y.shape)\n",
    "scaler = MinMaxScaler()\n",
    "# store them in this dataframe\n",
    "test_x=pd.DataFrame(scaler.fit_transform(test_x.astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "expressed-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First: generate predicted, class labels\n",
    "test_y_preds = predictor.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "effective-clearing",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ac2934792df8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_pred' is not defined"
     ]
    }
   ],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = 'SVR_tms_rbg_c100_g10e-1_e10e-1'\n",
    "\n",
    "# df_pred = pd.DataFrame(test_y_preds)\n",
    "df_y = pd.DataFrame(test_y)\n",
    "df_pred = pd.DataFrame(test_y_preds)\n",
    "\n",
    "df_output = pd.merge(df_pred, df_y, left_index=True, right_index=True)\n",
    "df_output = df_output.rename(columns={0: \"pred\", 6: \"actual\"})\n",
    "df_output.to_csv(\"output/{}.csv\".format(output_file_name),index=False)\n",
    "\n",
    "\n",
    "fig, (ax1) = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "\n",
    "ax1.plot(df_pred[0])\n",
    "ax1.plot(df_y[6])\n",
    "ax1.set_title('{}: DEC 2020'.format('Taipei Main Station'), fontsize=20)\n",
    "\n",
    "\n",
    "plt.savefig(\"output/{}.png\".format(output_file_name))\n",
    "plt.show()\n",
    "#fill_holidays(df_plot1, ax1_weekends, ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "played-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
